
####### modify
hydra:
  run:
    dir: ${log.project_folder}/${log.run_name}/configs
    # dir: ./

defaults:
  - _self_
  - encoder_model: efficientnet
  - policy_model: vint 
  - datasets: follow_in_broadcom_lab
  # - log: defaults

# training setup
training:
  batch_size: 16
  eval_batch_size: 32
  epochs: 15
  current_epoch: 0
  gpu_ids: [0]
  num_workers: 12
  lr: 1e-4 # 5e-4
  optimizer: adamw
  clipping: False
  max_norm: 1.
  scheduler: cosine
  warmup: False 
  warmup_epochs: 4
  cyclic_period: 10
  plateau_patience: 3
  plateau_factor: 0.5
  seed: 42
  goal_condition: False # not in use
  alpha: 0.5 # not in use
  beta: 10 # not in use

device: cuda

data:
  # normalization for the action space
  # normalization in the dataset class at data/pilot_dataset.py
  normalize: True
  # context
  context_type: temporal
  target_context: True
  context_size: 5
  distance:
    min_dist_cat: 0
    max_dist_cat: 10
  action:
    min_dist_cat: 0
    max_dist_cat: 20
  close_far_threshold: 30 # need to check 
  # distance threshold used to seperate the close and the far subgoals that are sampled per datapoint
  # action output params
  len_traj_pred: 5
  learn_angle: True
  # dataset specific parameters
  image_size: [85, 64] # width, height
  goal_type: "image"
  obs_type: "image"
  img_type: "depth" # if obs_type = image->  depth (1) | rgb (3) 
                    # do not forget to change the in_channels param in encoder_model as well



# logging stuff
log:
  project_folder: /home/roblab20/dev/pilot/pilot_bc/pilot_train/logs
  run_name: train_pilot_policy/${policy_model.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
  ## =0 turns off
  num_images_log: 8
  print_log_freq: 100 # in iterations
  image_log_freq: 1000 #0 # in iterations
  eval_fraction: 0.25
  eval_freq: 1 # in epochs

  wandb: 
    run: 
      enable: true
      name: ${log.run_name} ## modify
      log_freq: 10 # in iterations
    setup:
      project: pilot-release
      entity: nimrodcurtis
      mode: online

####### was ##########

# # model params
# model_type: vint
# obs_encoder: "efficientnet-b0" # by default, this is imagenet pretrained
# obs_encoding_size: 512
# mha_num_attention_heads: 4
# mha_num_attention_layers: 4
# mha_ff_dim_factor: 4
# late_fusion: False

# normalization for the action space
# normalization in the dataset class at data/pilot_dataset.py
# normalize: True

# # context
# context_type: temporal
# context_size: 5

# tradeoff between action and distance prediction loss
# alpha: 0.5
# beta: 10

# distance bounds for distance and action and distance predictions 
# distance:
#   min_dist_cat: 0
#   max_dist_cat: 20
# action:
#   min_dist_cat: 0
#   max_dist_cat: 10
# close_far_threshold: 10 # distance threshold used to seperate the close and the far subgoals that are sampled per datapoint

# # action output params
# len_traj_pred: 5
# learn_angle: True


# # dataset specific parameters
# image_size: [85, 64] # width, height
# goal_type: "image"

# use_wandb: True # set to false if you don't want to log to wandb
# train: True