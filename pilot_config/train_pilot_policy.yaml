
hydra:
  run:
    dir: ${log.project_folder}/${log.run_name}/configs

defaults:
  - _self_
  - linear_encoder: mlp       # mlp | tcn | ..
  - vision_encoder: depth_feature_extractor # depth_feature_extractor | efficientnet
  - policy_model: pidiff       # pidiff | vint | .. 
  - datasets: pilot_target_tracking # all | go_to_the_picture
  # - log: defaults


# device setup
device: cuda

# training setup
training:
  # goal_condition: True
  batch_size: 20
  eval_batch_size: 32
  epochs: 50
  current_epoch: 0
  gpu_ids: [0]
  num_workers: 12
  lr: 1e-4 # 5e-4 5e-5 1e-5 1e-4  
  optimizer: adamw
  clipping: True # Clip gradients
  clipping_max_norm: 1.
  scheduler: cosine  # cyclic | cosine | plateau
  warmup_steps: 500
  gradient_accumulate_every: 1

  warmup: True 
  warmup_epochs: 4
  cyclic_period: 10
  plateau_patience: 3
  plateau_factor: 0.5
  seed: 42
  use_ema: True 
  ema:
    _target_: diffusers.training_utils.EMAModel
    update_after_step: 0
    inv_gamma: 1.0
    power: 0.75
    min_decay: 0.0
    decay: 0.9999

  goal_mask_prob: 0.2 # 0 for no mask att all -> task specific
                      # 1 for mask all -> task agnostic, only explore
                      # p ~ (0,1) -> task specific with some explorations capabilities
  modal_dropout_prob: 0.00 # 0 for no no dropout , 1 for dropout one modal anytime

  debug:
    # steps per epoch
    max_train_steps: null
    max_val_steps: null


# data config
data:
  goal_condition: True

  # normalization for the action space
  # normalization in the dataset class at data/pilot_dataset.py
  normalize: True
  # context
  context_type: temporal
  target_observation_enable: True
  context_size: 5
  action_context_size: 3 # modify to 0 for not using actions history
  target_context: True
  target_dim: 2 # 3 for [d,cos(theta),sin(theta)] | 2 for [x,y]

  distance:
    min_dist_cat: 10
    max_dist_cat: 64
  action:
    min_dist_cat: 10
    max_dist_cat: 60

  # action output params
  pred_horizon: 64 
  action_horizon: 32
  learn_angle: True
  # dataset specific parameters
  image_size: [96, 96] # width, height
  # image_size: [85, 64] # width, height
  goal_type: "image"
  obs_type: "image"
  img_type: "depth" # if obs_type = image->  depth (1) | rgb (3) 
                    # do not forget to change the in_channels param in encoder_model as well

# logging config
log:
  desc: "pilot_bsz${training.batch_size}_c${data.context_size}_ac${data.action_context_size}_gcp${training.goal_mask_prob}_mdp${training.modal_dropout_prob}_ph${data.pred_horizon}"
  # desc: batch_experiment_b${training.batch_size}_
  
  project_folder: /home/roblab20/dev/pilot/pilot_bc/pilot_train/logs
  # project_folder: /home/nimrod/dev/pilot/pilot_bc/pilot_train/logs
  # project_folder: /home/curtis/dev/pilot/pilot_bc/pilot_train/logs

  run_name: train_pilot_policy/${policy_model.name}/${log.desc}${now:%Y-%m-%d}_${now:%H-%M-%S}
  ## =0 turns off
  
  ## TODO: handle with log and iamges 
  num_images_log: 4
  print_log_freq: 300 # in iterations
  eval_log_freq: 5  # in iterations
  image_log_freq: 5 # # in iterations
  eval_fraction: 0.25
  eval_freq: 1 # in epochs
  save_model_freq: 10
  wandb: 
    run: 
      enable: true
      name: ${log.run_name} ## modify
      log_freq: 10 # in iterations
    setup:
      project: pilot-release
      entity: nimrodcurtis
      mode: online