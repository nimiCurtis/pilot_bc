
hydra:
  run:
    dir: ${log.project_folder}/${log.run_name}/configs

defaults:
  - _self_
  - linear_encoder: mlp       # mlp | tcn | ..
  - vision_encoder: depth_feature_extractor # depth_feature_extractor | efficientnet
  - policy_model: cnn_mlp       # pidiff | vint | .. 
  - datasets: pilot_target_tracking_static # all | go_to_the_picture
  - log: local



# device setup
device: cuda

# training setup
training:
  # goal_condition: True
  batch_size: 16
  eval_batch_size: 32
  epochs: 20
  current_epoch: 0
  gpu_ids: [0]
  num_workers: 12
  lr: 1e-3 # 5e-4 5e-5 1e-5 1e-4  
  optimizer: adamw
  clipping: True # Clip gradients
  clipping_max_norm: 1.
  scheduler: cosine  # cyclic | cosine | plateau
  warmup_steps: 3
  gradient_accumulate_every: 1

  warmup: True 
  warmup_epochs: 4
  cyclic_period: 10
  plateau_patience: 3
  plateau_factor: 0.5
  seed: 42
  use_ema: True 
  ema:
    _target_: diffusers.training_utils.EMAModel
    update_after_step: 0
    inv_gamma: 1.0
    power: 0.75
    min_decay: 0.0
    decay: 0.9999

  goal_mask_prob: 0.1 # 0 for no mask att all -> task specific
                      # 1 for mask all -> task agnostic, only explore
                      # p ~ (0,1) -> task specific with some explorations capabilities
  modal_dropout_prob: 0.00 # 0 for no no dropout , 1 for dropout one modal anytime

  regularized_loss: True # l2 regularization
  debug:
    # steps per epoch
    max_train_steps: null
    max_val_steps: null


# data config
data:
  goal_condition: False # Always 
  target_context_enable: True

  # normalization for the action space
  # normalization in the dataset class at data/pilot_dataset.py
  normalize: True
  norm_type: maxmin   # maxmin | standard
  
  # context
  context_type: temporal
  context_size: 1
  action_context_size: 1 # modify to 0 for not using actions history
  target_dim: 2 # 3 for [d,cos(theta),sin(theta)] | 2 for [x,y]

# Take the distances with relate to the horizon
  distance:
    min_dist_cat: 24
    max_dist_cat: 40
  action:
    min_dist_cat: 24
    max_dist_cat: 40

  # action output params
  pred_horizon: 32 
  action_horizon: 16
  learn_angle: True
  # dataset specific parameters
  image_size: [96, 96] # width, height
  # image_size: [85, 64] # width, height
  goal_type: "image"
  obs_type: "image"
  img_type: "depth" # if obs_type = image->  depth (1) | rgb (3) 
                    # do not forget to change the in_channels param in encoder_model as well
